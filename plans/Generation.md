# Generation Process: Use Cases (JSON-Driven Platform)

This document outlines the "behind-the-scenes" use cases performed by the system to generate a lecture based on the pre-defined JSON structure.

### Use Case 1: Authenticate with Firebase
Before any other steps are taken, the system must authenticate with Google to gain access to Firebase services. It will use the credentials provided in a `firebase-web.json` file located in the application's root directory to sign in. All subsequent operations involving Firebase Storage will be performed using this authenticated session.

### Use Case 2: Load Lecture Definition
The generation process is initiated by the teacher. By default, the system is pre-configured to use the JSON data from `https://firebasestorage.googleapis.com/v0/b/gemini-vibeathon.firebasestorage.app/o/plans%2FTWI1750.json?alt=media` as the lecture data source. While the teacher can choose to provide alternative files, the system receives these defaults if no overrides are provided. It also receives any other customizations the teacher made (e.g., a custom video prompt or quiz length).

### Use Case 3: Generate Multimedia Content
Using the structured content from the JSON file, the system generates the necessary multimedia assets. To improve efficiency, the generation of video, audio, and any additional images should be performed in parallel.

*   **Parallel Task 1: Audio Generation:**
    *   It generates an audio narration of the main lecture text using **Gemini TTS**. The audio is synthesized from the `details` of the `content_and_themes` sections in the JSON file. The voice style is based on the teacher's selection.

*   **Parallel Task 2: Video Generation:**
    *   First, the system downloads the image from `https://firebasestorage.googleapis.com/v0/b/gemini-vibeathon.firebasestorage.app/o/media%2Falex.jpg?alt=media` into memory.
    *   This image data is then passed to **Nano Banana** to generate an initial frame.
    *   Once the initial frame is ready, the system creates a short introductory video using the **Veo3 (fast)** model. The content for this video is guided by the teacher's custom prompt, or if none is provided, it's based on the `overview` and `guiding_questions` from the JSON file.

*   **Parallel Task 3: Static Image Generation:**
    *   Any additional static images required for the lecture will be generated using **Nano Banana**.

### Use Case 4: Generate Quiz
The system generates a set of quiz questions and answers based on the `content_and_themes`. The number of questions is determined by the teacher's selection during the customization step.

### Use Case 5: Store Multimedia Assets in Cloud
All generated binary assets (the video file, audio files, images) are uploaded to a dedicated Firebase Storage bucket. The system receives a permanent, publicly accessible URL for each uploaded asset.

### Use Case 6: Assemble the Final HTML
The system generates a single, self-contained `index.html` file that functions as a slideshow. This involves:
*   **Creating a Slide Structure:** The HTML will contain a series of `<div>`s or similar elements, each representing a single "slide".
*   **Embedding Styles and Layout:**
    *   All necessary CSS for styling and slide navigation will be embedded directly within the HTML file in a `<style>` tag.
    *   The CSS must ensure the HTML body and its primary container take up the full height of the viewport.
    *   The layout must be responsive and optimized for a minimum resolution of 1280x720.
*   **Populating Slides:**
    *   The first slide is populated with the introductory video.
    *   The system then divides the main lecture text (from the `content_and_themes` in the JSON) into logical chunks.
    *   **Markdown Rendering:** Any content sourced from the JSON (e.g., the `details` field) that contains Markdown syntax must be parsed and converted into correctly styled HTML (e.g., `## Header` becomes `<h2>Header</h2>`).
    *   Each chunk of rendered text and its corresponding audio narration is placed into its own slide.
    *   The final slides are populated with the quiz questions.
*   **Linking Cloud Assets:** The system inserts the public Firebase Storage URLs for the video and audio files into the `src` attributes of the `<video>` and `<audio>` tags on their respective slides.

### Use Case 7: Upload HTML to Firebase Storage
Once the `index.html` file is fully assembled, it is uploaded to the `lectures` directory within a designated Firebase Storage bucket. The file is named using the convention: `<grade>-<subject>-<lesson-title>.html`.

The `<lesson-title>` segment is generated by taking the `title` field from the lecture's JSON metadata and converting it to kebab-case (e.g., "The World in 1750" becomes "the-world-in-1750"). This involves making the string all lowercase, replacing spaces with dashes, and removing any special characters other than dashes. This makes the lecture accessible for both teachers and students via a predictable URL.
